#! /usr/bin/env python3
#
# Consider a configuration of
#
# on-no-quorum suspend-io;
# on-no-data-accessible io-error;
# rr-conflict retry;
#
# When a primary looses quorum, IO freezes there. Now, in the other
# partition a node gets promoted to a new primary, and the other
# partition creates a new data generation.
#
# When the IO-frozen primary tries to reconnect to the larger
# partition, the attempt fails, because two partitions with a primary
# can not join. But with that it learns that it no longer has the
# lates up-to-date data. Therefore it completes the forzen IO requests
# with errors. Ideally that causes the application on top to terminate
# and when user-space is cooperative, it will even demote to
# secondary. (Containerized application terminates, causing the
# "persistent volume" to be unmounted -> drbd demotes to secondary)
# then at the next connect attempt it can connect to the larger
# partition, becomes sync target. Everyone is happy about a complete
# automatic recovery after a primary got isolated.

from python import drbdtest
from python.drbdtest import log

def write_on_node(node):
    v = node.volumes[0]
    # write 4K in background
    pid = node.run(['setsid', 'bash', '-c',
                   'dd if=/dev/urandom of={0} bs=4096 oflag=direct count=1 < /dev/null &> /dev/null & echo $!'
                   .format(v.device())], return_stdout=True)

    return pid

resource = drbdtest.setup(nodes=3)
resource.resource_options = 'quorum majority; on-no-quorum suspend-io; on-no-data-accessible io-error;'
resource.net_options = 'rr-conflict retry-connect;'
resource.add_disk('10M')
resource.up_wait()

node_a, node_b, node_c = resource.nodes

connection_ba = resource.connections.from_node(node_b).to_node(node_a)
connection_ca = resource.connections.from_node(node_c).to_node(node_a)
peer_devices_ab = resource.peer_devices.from_node(node_a).to_node(node_b)
peer_devices_ac = resource.peer_devices.from_node(node_a).to_node(node_c)

log('* Make up-to-date data available.')
resource.skip_initial_sync();

resource.forbidden_patterns.remove(r'connection:BrokenPipe')
resource.forbidden_patterns.remove(r'connection:NetworkFailure')

node_a.primary()
node_a.volumes.write(direct=1)

connection_ba.disconnect(force=True)
connection_ca.disconnect(force=True)

node_a.event(r'device .* quorum:no')
dd_pid = write_on_node(node_a)

node_b.primary()
node_b.volumes.write(direct=1)

connection_ba.connect()

node_a.run(['tail', '--pid={0}'.format(dd_pid), '-f', '/dev/null'])
node_a.secondary()

peer_devices_ab.event(r'peer-device .* replication:SyncTarget')
peer_devices_ab.event(r'peer-device .* replication:Established')
connection_ca.connect()
peer_devices_ac.event(r'peer-device .* replication:Established')

log('* Shut down and clean up.')

resource.down()
resource.teardown()
