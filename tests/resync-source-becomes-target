#! /usr/bin/env python3
### vmshed: { "vms_all": [3], "vms_ci": [3], "drbd_version_min": "9.0" }

# This test creats three different versions of the data. It let
# the two older nodes begin a resync. When they are in the middle
# of the resync operation, the node with the newest data connects
# to the resync source of the already running resync.
# It has to pause the running resync, obtain the newest data, and
# then continue the resync to the downstream peer.
#
# In variant two it starts the upstream resync after downstream
# completed

from python import drbdtest
from python.drbdtest import connections, log, peer_devices

def write_on_node(node, file_nr, megs):
    dev_name = node.volumes[0].device()

    node.run(['mkdir', '-p', '/mnt/1'])
    node.run(['mount', dev_name, '/mnt/1'])
    node.fio_file('/mnt/1/file%d' % (file_nr) , drbdtest.fio_write_args, size='%dM' % (megs), bs='1M')
    node.run(['umount', '/mnt/1'])

def disconnect_and_write(n, remaining, file_nr):
    connections(n).disconnect()
    to = connections(from_nodes=remaining, to_node=n)
    to.event(r'connection .* connection:TearDown')
    to.event(r'connection .* connection:Connecting')
    write_on_node(node_primary, file_nr, megs_per_file)

def connect_and_check(n1, n2):
    cs = connections(n1, n2, bidir=True)
    cs.connect()
    cs.event(r'connection .* connection:Connected')

def do_test(variant):
    log('* Variant %d of test' % (variant))
    # Iterate in reverse order so that the data generations are:
    # node_primary > node_s0 > node_s1
    disconnect_and_write(node_s1, [node_primary, node_s0], 0)
    disconnect_and_write(node_s0, [node_primary], 1)

    connections(node_primary).disconnect()

    log('* Start downstream resync.')

    cs = connections(node_s0, node_s1, bidir=True)
    pds = peer_devices(node_s0, node_s1, bidir=True)
    if variant == 1:
        pds.peer_device_options("--c-max-rate=5M")
    cs.connect()
    cs.event(r'connection .* connection:Connected')

    pd_s1_s0 = peer_devices(node_s1, node_s0)
    pd_s0_s1 = peer_devices(node_s0, node_s1)

    if variant == 1:
        # wait until events2 reports >= 10 % done
        done = pd_s1_s0.event(r'peer-device .* done:([1-9][0-9][0-9.]+)')
        log('* Start upstream resync at %s of downstream resync.' % (done[0][0]))
        pds.peer_device_options("--c-max-rate=60M")

    elif variant == 2:
        node_s1.volumes[0].event(r'device .* disk:UpToDate')
        pd_s0_s1.event(r'peer-device .* peer-disk:UpToDate')
        log('* Start upstream resync after downstream resync finished')

    connect_and_check(node_primary, node_s0)

    pd_primary_s0 = peer_devices(node_primary, node_s0)

    log('* Wait for upstream resync')
    node_s0.volumes[0].event(r'device .* disk:UpToDate')
    pd_primary_s0.event(r'peer-device .* peer-disk:UpToDate')

    log('* Wait for downstream resync as a result of upstream resync')
    node_s1.volumes[0].event(r'device .* disk:UpToDate')
    pd_s0_s1.event(r'peer-device .* peer-disk:UpToDate')

    connect_and_check(node_primary, node_s1)

# main
megs = 100

resource = drbdtest.setup_resource(nodes=3)
resource.disk_options = 'c-max-rate 60M;'
resource.add_disk('%dM' % (megs))
resource.up_wait()

log('* Make up-to-date data available.')
resource.skip_initial_sync()

node_primary, node_s0, node_s1 = resource.nodes
dev_name = node_primary.volumes[0].device()
megs_per_file = (megs * 8 / 10) / (len(resource.nodes) - 1)

node_primary.run(['mkfs', '-t', 'ext4', dev_name])

do_test(1)
do_test(2)

log('* Shut down and clean up.')
node_primary.run(['wipefs', dev_name])
resource.down()
# An assertion sometimes fails when running this test. Disable validation until
# the issue is fixed in DRBD.
resource.cluster.teardown(validate_dmesg=False)
