#! /usr/bin/env python3
#
# Interesting that this issue survived for so long!!
# Consider 3 nodes: A, B, C. (A = Primary, Quorum enabled)
# Down C (gracefully)
# Down B (gracefully, allows A to keep quorum due to "Last man standing"
# Let C resync to A
# Connect B to C and see a split brain up to DRBD 9.0.21!!


from python import drbdtest
from python.drbdtest import verbose
from subprocess import CalledProcessError

resource = drbdtest.setup(min_nodes=3, max_nodes=3)
resource.resource_options = 'quorum majority; on-no-quorum io-error;'
resource.add_disk('10M')

resource.up_wait()

verbose('* Make up-to-date data available.')
resource.skip_initial_sync()

[node_a, node_b, node_c] = resource.nodes
dev_name = node_a.volumes[0].device()

node_a.primary()
connections_to_a = resource.connections.to_node(node_a)
connections_to_a.event(r'connection .* role:Primary')

resource.connections.from_node(node_c).disconnect()
node_a.run(['dd', 'if=/dev/zero', 'of=%s' % (dev_name), 'bs=1024', 'count=1'])

resource.connections.from_node(node_b).disconnect()
node_a.run(['dd', 'if=/dev/zero', 'of=%s' % (dev_name), 'bs=1024', 'count=1'])

drbdtest.Connection(node_c, node_a).connect()
node_c.volumes.event(r'device .* disk:UpToDate')

connections_bc = drbdtest.Connections()
connections_bc.bidir_add(node_b, node_c)
connections_bc.connect()
peer_devices = drbdtest.PeerDevices.from_connections(connections_bc)
peer_devices.event(r'peer-device .* replication:Established')

verbose('* Shut down and clean up.')
resource.down()
resource.rmmod()
